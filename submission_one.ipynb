{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:35.195651Z","iopub.execute_input":"2025-02-09T02:57:35.196008Z","iopub.status.idle":"2025-02-09T02:57:35.206164Z","shell.execute_reply.started":"2025-02-09T02:57:35.195980Z","shell.execute_reply":"2025-02-09T02:57:35.205062Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e2/sample_submission.csv\n/kaggle/input/playground-series-s5e2/train.csv\n/kaggle/input/playground-series-s5e2/test.csv\n/kaggle/input/playground-series-s5e2/training_extra.csv\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s5e2/train.csv', index_col=['id'])\ntest = pd.read_csv('/kaggle/input/playground-series-s5e2/test.csv', index_col=['id'])\n\ntrain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:35.207665Z","iopub.execute_input":"2025-02-09T02:57:35.207949Z","iopub.status.idle":"2025-02-09T02:57:35.921697Z","shell.execute_reply.started":"2025-02-09T02:57:35.207923Z","shell.execute_reply":"2025-02-09T02:57:35.920620Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"               Brand Material    Size  Compartments Laptop Compartment  \\\nid                                                                       \n0           Jansport  Leather  Medium           7.0                Yes   \n1           Jansport   Canvas   Small          10.0                Yes   \n2       Under Armour  Leather   Small           2.0                Yes   \n3               Nike    Nylon   Small           8.0                Yes   \n4             Adidas   Canvas  Medium           1.0                Yes   \n...              ...      ...     ...           ...                ...   \n299995        Adidas  Leather   Small           9.0                 No   \n299996      Jansport  Leather   Large           6.0                 No   \n299997          Puma   Canvas   Large           9.0                Yes   \n299998        Adidas    Nylon   Small           1.0                 No   \n299999  Under Armour   Canvas   Small           2.0                 No   \n\n       Waterproof      Style  Color  Weight Capacity (kg)      Price  \nid                                                                    \n0              No       Tote  Black             11.611723  112.15875  \n1             Yes  Messenger  Green             27.078537   68.88056  \n2              No  Messenger    Red             16.643760   39.17320  \n3              No  Messenger  Green             12.937220   80.60793  \n4             Yes  Messenger  Green             17.749338   86.02312  \n...           ...        ...    ...                   ...        ...  \n299995         No       Tote   Blue             12.730812  129.99749  \n299996        Yes       Tote   Blue             26.633182   19.85819  \n299997        Yes   Backpack   Pink             11.898250  111.41364  \n299998        Yes       Tote   Pink              6.175738  115.89080  \n299999        Yes   Backpack  Black             18.568865   26.72762  \n\n[300000 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jansport</td>\n      <td>Leather</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>11.611723</td>\n      <td>112.15875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jansport</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>27.078537</td>\n      <td>68.88056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Under Armour</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Red</td>\n      <td>16.643760</td>\n      <td>39.17320</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>12.937220</td>\n      <td>80.60793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>17.749338</td>\n      <td>86.02312</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>Adidas</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>12.730812</td>\n      <td>129.99749</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>Jansport</td>\n      <td>Leather</td>\n      <td>Large</td>\n      <td>6.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>26.633182</td>\n      <td>19.85819</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>Puma</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>9.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Pink</td>\n      <td>11.898250</td>\n      <td>111.41364</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>Adidas</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Pink</td>\n      <td>6.175738</td>\n      <td>115.89080</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>Under Armour</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Black</td>\n      <td>18.568865</td>\n      <td>26.72762</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:35.923656Z","iopub.execute_input":"2025-02-09T02:57:35.924027Z","iopub.status.idle":"2025-02-09T02:57:36.045646Z","shell.execute_reply.started":"2025-02-09T02:57:35.923995Z","shell.execute_reply":"2025-02-09T02:57:36.044366Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 300000 entries, 0 to 299999\nData columns (total 10 columns):\n #   Column                Non-Null Count   Dtype  \n---  ------                --------------   -----  \n 0   Brand                 290295 non-null  object \n 1   Material              291653 non-null  object \n 2   Size                  293405 non-null  object \n 3   Compartments          300000 non-null  float64\n 4   Laptop Compartment    292556 non-null  object \n 5   Waterproof            292950 non-null  object \n 6   Style                 292030 non-null  object \n 7   Color                 290050 non-null  object \n 8   Weight Capacity (kg)  299862 non-null  float64\n 9   Price                 300000 non-null  float64\ndtypes: float64(3), object(7)\nmemory usage: 25.2+ MB\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"*Create a pairplot*","metadata":{}},{"cell_type":"markdown","source":"*Get numeric columns and categorical columns*","metadata":{}},{"cell_type":"code","source":"num_df = train.select_dtypes(include=['number']).drop('Price', axis=1)\ncat_df = train.select_dtypes(include=['object'])\n\nnum_cols = num_df.columns\ncat_cols = cat_df.columns\n\nnum_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:36.047679Z","iopub.execute_input":"2025-02-09T02:57:36.048508Z","iopub.status.idle":"2025-02-09T02:57:36.083846Z","shell.execute_reply.started":"2025-02-09T02:57:36.048446Z","shell.execute_reply":"2025-02-09T02:57:36.082729Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"        Compartments  Weight Capacity (kg)\nid                                        \n0                7.0             11.611723\n1               10.0             27.078537\n2                2.0             16.643760\n3                8.0             12.937220\n4                1.0             17.749338\n...              ...                   ...\n299995           9.0             12.730812\n299996           6.0             26.633182\n299997           9.0             11.898250\n299998           1.0              6.175738\n299999           2.0             18.568865\n\n[300000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compartments</th>\n      <th>Weight Capacity (kg)</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>11.611723</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.0</td>\n      <td>27.078537</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>16.643760</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.0</td>\n      <td>12.937220</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>17.749338</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>9.0</td>\n      <td>12.730812</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>6.0</td>\n      <td>26.633182</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>9.0</td>\n      <td>11.898250</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>1.0</td>\n      <td>6.175738</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>2.0</td>\n      <td>18.568865</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"*Seperate categorical columns into ordinal (to be ordinal encoded) and non-ordinal (to be one-hot encoded)*","metadata":{}},{"cell_type":"markdown","source":"# TODO: Try changing the ordinal and non-ordinal columns around","metadata":{}},{"cell_type":"code","source":"ord_cols = ['Size', 'Laptop Compartment', 'Waterproof']\noh_cols = ['Brand', 'Material', 'Style', 'Color']\n\nord_df = train[ord_cols]\noh_df = train[oh_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:36.085036Z","iopub.execute_input":"2025-02-09T02:57:36.085443Z","iopub.status.idle":"2025-02-09T02:57:36.109337Z","shell.execute_reply.started":"2025-02-09T02:57:36.085381Z","shell.execute_reply":"2025-02-09T02:57:36.108341Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"*Get unique values*","metadata":{}},{"cell_type":"code","source":"for col in ord_df.columns:\n    print(f'col: {col}\\n\\\nvalues: {ord_df[col].unique()}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:36.110459Z","iopub.execute_input":"2025-02-09T02:57:36.110874Z","iopub.status.idle":"2025-02-09T02:57:36.156464Z","shell.execute_reply.started":"2025-02-09T02:57:36.110831Z","shell.execute_reply":"2025-02-09T02:57:36.154517Z"}},"outputs":[{"name":"stdout","text":"col: Size\nvalues: ['Medium' 'Small' 'Large' nan]\ncol: Laptop Compartment\nvalues: ['Yes' 'No' nan]\ncol: Waterproof\nvalues: ['No' 'Yes' nan]\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"*Get the ordering of columns in the `train` DataFrame*","metadata":{}},{"cell_type":"code","source":"for i, col in enumerate(train.columns):\n    print(f'{i}, {col}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:36.160605Z","iopub.execute_input":"2025-02-09T02:57:36.161006Z","iopub.status.idle":"2025-02-09T02:57:36.185500Z","shell.execute_reply.started":"2025-02-09T02:57:36.160970Z","shell.execute_reply":"2025-02-09T02:57:36.184202Z"}},"outputs":[{"name":"stdout","text":"0, Brand\n1, Material\n2, Size\n3, Compartments\n4, Laptop Compartment\n5, Waterproof\n6, Style\n7, Color\n8, Weight Capacity (kg)\n9, Price\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":" *Define ordering for each value*","metadata":{}},{"cell_type":"code","source":"size_categories = ['Small', 'Medium', 'Large']\nyesno_categories = ['No', 'Yes']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:36.187291Z","iopub.execute_input":"2025-02-09T02:57:36.187659Z","iopub.status.idle":"2025-02-09T02:57:36.204712Z","shell.execute_reply.started":"2025-02-09T02:57:36.187626Z","shell.execute_reply":"2025-02-09T02:57:36.203557Z"}},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":"*Create transformers for each type of column*","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, FunctionTransformer\n\n# Numerical columns\n\nnum_transformer = Pipeline(\n    steps=[\n        ('num_impute', SimpleImputer(strategy='median')),\n        ('scale', StandardScaler()),\n    ]\n)\n\nnum_df = pd.DataFrame(num_transformer.fit_transform(num_df))\nnum_df.columns = num_cols\n\n# For ordinal columns\n\nord_preprocessor = ColumnTransformer(\n    transformers=[\n        ('size_encoder', OrdinalEncoder(categories=[size_categories], ), ['Size']),\n        ('laptop_encoder', OrdinalEncoder(categories=[yesno_categories]), ['Laptop Compartment']),\n        ('wp_encoder', OrdinalEncoder(categories=[yesno_categories]), ['Waterproof'])\n    ],\n    remainder='passthrough'\n)\n\nord_transformer = Pipeline(\n    steps=[\n        ('ord_impute', SimpleImputer(strategy='most_frequent')),\n        ('df_conversion', FunctionTransformer(lambda x: pd.DataFrame(x, columns=ord_cols))),\n        ('preprocess', ordinal_preprocessor)\n    ]\n)\n\nord_df = pd.DataFrame(ord_transformer.fit_transform(ord_df), columns = ord_cols)\n\n# One hot columns\n\noh_transformer = Pipeline(\n    steps=[\n        ('oh_impute', SimpleImputer(strategy='most_frequent')),\n        ('oh_encode', OneHotEncoder(handle_unknown='ignore', sparse=False))\n    ]\n)\n\noh_df = pd.DataFrame(oh_transformer.fit_transform(oh_df))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:57:36.205858Z","iopub.execute_input":"2025-02-09T02:57:36.206181Z","iopub.status.idle":"2025-02-09T02:57:37.299005Z","shell.execute_reply.started":"2025-02-09T02:57:36.206153Z","shell.execute_reply":"2025-02-09T02:57:37.297867Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nmy_model = xgb.XGBRegressor(objective='reg:squarederror',\n                        n_estimators=500)\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num', num_transformer, num_cols),\n        ('ord', ord_transformer, ord_cols),\n        ('oh', oh_transformer, oh_cols)\n    ],\n    remainder = 'passthrough'\n)\n\npipeline = Pipeline(\n    steps = [\n        ('preprocessor', preprocessor),\n        ('predict', my_model)\n    ]\n)\n\nX_train, X_valid, y_train, y_valid = train_test_split(train.drop(columns=['Price']), train['Price'], test_size=0.2, random_state=42)\n\npipeline.fit(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T03:17:23.853747Z","iopub.execute_input":"2025-02-09T03:17:23.854173Z","iopub.status.idle":"2025-02-09T03:17:25.532906Z","shell.execute_reply.started":"2025-02-09T03:17:23.854136Z","shell.execute_reply":"2025-02-09T03:17:25.531275Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-d6cb43871827>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             )\n\u001b[0;32m-> 1090\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1091\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m             _check_call(\n\u001b[0m\u001b[1;32m   2051\u001b[0m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[1;32m   2052\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mXGBoostError\u001b[0m: [03:17:25] /workspace/src/objective/init_estimation.h:16: Check failed: info.labels.Shape(0) == info.num_row_ (0 vs. 240000) : Invalid shape of labels.\nStack trace:\n  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x1ba24e) [0x7c0e8f33724e]\n  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x55fbd4) [0x7c0e8f6dcbd4]\n  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4900d1) [0x7c0e8f60d0d1]\n  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c0716) [0x7c0e8f63d716]\n  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c5274) [0x7c0e8f642274]\n  [bt] (5) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7c0e8f2deef0]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7c0f0671fe2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7c0f0671c493]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7c0f067463e9]\n\n"],"ename":"XGBoostError","evalue":"[03:17:25] /workspace/src/objective/init_estimation.h:16: Check failed: info.labels.Shape(0) == info.num_row_ (0 vs. 240000) : Invalid shape of labels.\nStack trace:\n  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x1ba24e) [0x7c0e8f33724e]\n  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x55fbd4) [0x7c0e8f6dcbd4]\n  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4900d1) [0x7c0e8f60d0d1]\n  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c0716) [0x7c0e8f63d716]\n  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c5274) [0x7c0e8f642274]\n  [bt] (5) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7c0e8f2deef0]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7c0f0671fe2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7c0f0671c493]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7c0f067463e9]\n\n","output_type":"error"}],"execution_count":62},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T03:08:51.405627Z","iopub.execute_input":"2025-02-09T03:08:51.405994Z","iopub.status.idle":"2025-02-09T03:08:51.421601Z","shell.execute_reply.started":"2025-02-09T03:08:51.405965Z","shell.execute_reply":"2025-02-09T03:08:51.420549Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"               Brand   Material    Size  Compartments Laptop Compartment  \\\nid                                                                         \n300000          Puma    Leather   Small           2.0                 No   \n300001          Nike     Canvas  Medium           7.0                 No   \n300002        Adidas     Canvas   Large           9.0                 No   \n300003        Adidas      Nylon   Large           1.0                Yes   \n300004           NaN      Nylon   Large           2.0                Yes   \n...              ...        ...     ...           ...                ...   \n499995        Adidas     Canvas   Large           2.0                Yes   \n499996          Nike  Polyester   Small           9.0                 No   \n499997      Jansport      Nylon   Small           9.0                 No   \n499998          Puma      Nylon   Large          10.0                Yes   \n499999  Under Armour    Leather  Medium           8.0                Yes   \n\n       Waterproof      Style  Color  Weight Capacity (kg)  \nid                                                         \n300000         No       Tote  Green             20.671147  \n300001        Yes   Backpack  Green             13.564105  \n300002        Yes  Messenger   Blue             11.809799  \n300003         No  Messenger  Green             18.477036  \n300004        Yes       Tote  Black              9.907953  \n...           ...        ...    ...                   ...  \n499995         No  Messenger    Red              7.383498  \n499996        Yes  Messenger   Pink              6.058394  \n499997        Yes       Tote  Green             26.890163  \n499998         No       Tote   Gray             25.769153  \n499999        Yes  Messenger   Pink             29.175026  \n\n[200000 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>300000</th>\n      <td>Puma</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Green</td>\n      <td>20.671147</td>\n    </tr>\n    <tr>\n      <th>300001</th>\n      <td>Nike</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Green</td>\n      <td>13.564105</td>\n    </tr>\n    <tr>\n      <th>300002</th>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Blue</td>\n      <td>11.809799</td>\n    </tr>\n    <tr>\n      <th>300003</th>\n      <td>Adidas</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>18.477036</td>\n    </tr>\n    <tr>\n      <th>300004</th>\n      <td>NaN</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>9.907953</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499995</th>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Red</td>\n      <td>7.383498</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>Nike</td>\n      <td>Polyester</td>\n      <td>Small</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Pink</td>\n      <td>6.058394</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>Jansport</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Green</td>\n      <td>26.890163</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>Puma</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Gray</td>\n      <td>25.769153</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>Under Armour</td>\n      <td>Leather</td>\n      <td>Medium</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Pink</td>\n      <td>29.175026</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":57}]}