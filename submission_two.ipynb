{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:37:57.851450Z","iopub.execute_input":"2025-02-14T16:37:57.851766Z","iopub.status.idle":"2025-02-14T16:37:59.707257Z","shell.execute_reply.started":"2025-02-14T16:37:57.851740Z","shell.execute_reply":"2025-02-14T16:37:59.706089Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e2/sample_submission.csv\n/kaggle/input/playground-series-s5e2/train.csv\n/kaggle/input/playground-series-s5e2/test.csv\n/kaggle/input/playground-series-s5e2/training_extra.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# NOTE: Compared to version 1, This version uses LGBM instead of XGB","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s5e2/train.csv', index_col=['id'])\ntest = pd.read_csv('/kaggle/input/playground-series-s5e2/test.csv', index_col=['id'])\ntrain_xtra = pd.read_csv('/kaggle/input/playground-series-s5e2/training_extra.csv', index_col=['id'])\n\ntrain_xtra","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:23:20.996463Z","iopub.execute_input":"2025-02-14T17:23:20.996867Z","iopub.status.idle":"2025-02-14T17:23:27.255727Z","shell.execute_reply.started":"2025-02-14T17:23:20.996836Z","shell.execute_reply":"2025-02-14T17:23:27.254779Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"                Brand   Material    Size  Compartments Laptop Compartment  \\\nid                                                                          \n500000   Under Armour     Canvas   Small          10.0                Yes   \n500001           Puma  Polyester   Small           4.0                 No   \n500002       Jansport  Polyester   Small           8.0                Yes   \n500003           Nike      Nylon   Large           7.0                 No   \n500004           Nike    Leather   Large           9.0                 No   \n...               ...        ...     ...           ...                ...   \n4194313          Nike     Canvas     NaN           3.0                Yes   \n4194314          Puma    Leather   Small          10.0                Yes   \n4194315      Jansport     Canvas   Large          10.0                 No   \n4194316          Puma     Canvas     NaN           2.0                 No   \n4194317  Under Armour  Polyester  Medium           2.0                Yes   \n\n        Waterproof      Style  Color  Weight Capacity (kg)      Price  \nid                                                                     \n500000         Yes       Tote   Blue             23.882052  114.11068  \n500001         Yes   Backpack  Green             11.869095  129.74972  \n500002         Yes       Tote    Red              8.092302   21.37370  \n500003          No  Messenger   Pink              7.719581   48.09209  \n500004         Yes       Tote  Green             22.741826   77.32461  \n...            ...        ...    ...                   ...        ...  \n4194313        Yes  Messenger   Blue             28.098120  104.74460  \n4194314        Yes       Tote   Blue             17.379531  122.39043  \n4194315         No   Backpack    Red             17.037708  148.18470  \n4194316         No   Backpack   Gray             28.783339   22.32269  \n4194317         No   Backpack   Blue             23.076169  107.61199  \n\n[3694318 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>500000</th>\n      <td>Under Armour</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>23.882052</td>\n      <td>114.11068</td>\n    </tr>\n    <tr>\n      <th>500001</th>\n      <td>Puma</td>\n      <td>Polyester</td>\n      <td>Small</td>\n      <td>4.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Green</td>\n      <td>11.869095</td>\n      <td>129.74972</td>\n    </tr>\n    <tr>\n      <th>500002</th>\n      <td>Jansport</td>\n      <td>Polyester</td>\n      <td>Small</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Red</td>\n      <td>8.092302</td>\n      <td>21.37370</td>\n    </tr>\n    <tr>\n      <th>500003</th>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>7.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Pink</td>\n      <td>7.719581</td>\n      <td>48.09209</td>\n    </tr>\n    <tr>\n      <th>500004</th>\n      <td>Nike</td>\n      <td>Leather</td>\n      <td>Large</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Green</td>\n      <td>22.741826</td>\n      <td>77.32461</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4194313</th>\n      <td>Nike</td>\n      <td>Canvas</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Blue</td>\n      <td>28.098120</td>\n      <td>104.74460</td>\n    </tr>\n    <tr>\n      <th>4194314</th>\n      <td>Puma</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>17.379531</td>\n      <td>122.39043</td>\n    </tr>\n    <tr>\n      <th>4194315</th>\n      <td>Jansport</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>10.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Backpack</td>\n      <td>Red</td>\n      <td>17.037708</td>\n      <td>148.18470</td>\n    </tr>\n    <tr>\n      <th>4194316</th>\n      <td>Puma</td>\n      <td>Canvas</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Backpack</td>\n      <td>Gray</td>\n      <td>28.783339</td>\n      <td>22.32269</td>\n    </tr>\n    <tr>\n      <th>4194317</th>\n      <td>Under Armour</td>\n      <td>Polyester</td>\n      <td>Medium</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Backpack</td>\n      <td>Blue</td>\n      <td>23.076169</td>\n      <td>107.61199</td>\n    </tr>\n  </tbody>\n</table>\n<p>3694318 rows Ã— 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:38:09.939155Z","iopub.execute_input":"2025-02-14T16:38:09.939576Z","iopub.status.idle":"2025-02-14T16:38:10.063388Z","shell.execute_reply.started":"2025-02-14T16:38:09.939538Z","shell.execute_reply":"2025-02-14T16:38:10.062087Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 300000 entries, 0 to 299999\nData columns (total 10 columns):\n #   Column                Non-Null Count   Dtype  \n---  ------                --------------   -----  \n 0   Brand                 290295 non-null  object \n 1   Material              291653 non-null  object \n 2   Size                  293405 non-null  object \n 3   Compartments          300000 non-null  float64\n 4   Laptop Compartment    292556 non-null  object \n 5   Waterproof            292950 non-null  object \n 6   Style                 292030 non-null  object \n 7   Color                 290050 non-null  object \n 8   Weight Capacity (kg)  299862 non-null  float64\n 9   Price                 300000 non-null  float64\ndtypes: float64(3), object(7)\nmemory usage: 25.2+ MB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"*Create a pairplot*","metadata":{}},{"cell_type":"markdown","source":"*Get numeric columns and categorical columns*","metadata":{}},{"cell_type":"code","source":"num_df = train.select_dtypes(include=['number']).drop('Price', axis=1)\ncat_df = train.select_dtypes(include=['object'])\n\nnum_cols = num_df.columns\ncat_cols = cat_df.columns\n\nnum_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:38:10.064575Z","iopub.execute_input":"2025-02-14T16:38:10.065074Z","iopub.status.idle":"2025-02-14T16:38:10.094900Z","shell.execute_reply.started":"2025-02-14T16:38:10.065031Z","shell.execute_reply":"2025-02-14T16:38:10.093416Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        Compartments  Weight Capacity (kg)\nid                                        \n0                7.0             11.611723\n1               10.0             27.078537\n2                2.0             16.643760\n3                8.0             12.937220\n4                1.0             17.749338\n...              ...                   ...\n299995           9.0             12.730812\n299996           6.0             26.633182\n299997           9.0             11.898250\n299998           1.0              6.175738\n299999           2.0             18.568865\n\n[300000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compartments</th>\n      <th>Weight Capacity (kg)</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>11.611723</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.0</td>\n      <td>27.078537</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>16.643760</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.0</td>\n      <td>12.937220</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>17.749338</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>9.0</td>\n      <td>12.730812</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>6.0</td>\n      <td>26.633182</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>9.0</td>\n      <td>11.898250</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>1.0</td>\n      <td>6.175738</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>2.0</td>\n      <td>18.568865</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"*Seperate categorical columns into ordinal (to be ordinal encoded) and non-ordinal (to be one-hot encoded)*","metadata":{}},{"cell_type":"markdown","source":"# TODO: Try changing the ordinal and non-ordinal columns around","metadata":{}},{"cell_type":"code","source":"ord_cols = ['Size', 'Laptop Compartment', 'Waterproof']\noh_cols = ['Brand', 'Material', 'Style', 'Color']\n\nord_df = train[ord_cols]\noh_df = train[oh_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:38:10.095946Z","iopub.execute_input":"2025-02-14T16:38:10.096240Z","iopub.status.idle":"2025-02-14T16:38:10.116848Z","shell.execute_reply.started":"2025-02-14T16:38:10.096216Z","shell.execute_reply":"2025-02-14T16:38:10.115608Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"*Get unique values*","metadata":{}},{"cell_type":"code","source":"for col in ord_df.columns:\n    print(f'col: {col}\\n\\\nvalues: {ord_df[col].unique()}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:38:10.120379Z","iopub.execute_input":"2025-02-14T16:38:10.120720Z","iopub.status.idle":"2025-02-14T16:38:10.159337Z","shell.execute_reply.started":"2025-02-14T16:38:10.120667Z","shell.execute_reply":"2025-02-14T16:38:10.158079Z"}},"outputs":[{"name":"stdout","text":"col: Size\nvalues: ['Medium' 'Small' 'Large' nan]\ncol: Laptop Compartment\nvalues: ['Yes' 'No' nan]\ncol: Waterproof\nvalues: ['No' 'Yes' nan]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"*Get the ordering of columns in the `train` DataFrame*","metadata":{}},{"cell_type":"code","source":"for i, col in enumerate(train.columns):\n    print(f'{i}, {col}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:38:10.160972Z","iopub.execute_input":"2025-02-14T16:38:10.161295Z","iopub.status.idle":"2025-02-14T16:38:10.183713Z","shell.execute_reply.started":"2025-02-14T16:38:10.161269Z","shell.execute_reply":"2025-02-14T16:38:10.182552Z"}},"outputs":[{"name":"stdout","text":"0, Brand\n1, Material\n2, Size\n3, Compartments\n4, Laptop Compartment\n5, Waterproof\n6, Style\n7, Color\n8, Weight Capacity (kg)\n9, Price\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":" *Define ordering for each value*","metadata":{}},{"cell_type":"code","source":"size_categories = ['Small', 'Medium', 'Large']\nyesno_categories = ['No', 'Yes']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:38:10.184967Z","iopub.execute_input":"2025-02-14T16:38:10.185309Z","iopub.status.idle":"2025-02-14T16:38:10.202890Z","shell.execute_reply.started":"2025-02-14T16:38:10.185283Z","shell.execute_reply":"2025-02-14T16:38:10.201666Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"*Create transformers for each type of column*","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, FunctionTransformer\n\n# Using KNNImputer, n_neighbors is set arbitrarily, we'll go back later and figure out the best setting\n\n# Numerical columns\n\nnum_transformer = Pipeline(\n    steps=[\n        ('num_impute', SimpleImputer(strategy = 'median')),\n        ('scale', StandardScaler()),\n    ]\n)\n\nnum_df = pd.DataFrame(num_transformer.fit_transform(num_df))\nnum_df.columns = num_cols\n\n# For ordinal columns\n\nord_preprocessor = ColumnTransformer(\n    transformers=[\n        ('size_encoder', OrdinalEncoder(categories = [size_categories], handle_unknown = 'use_encoded_value', unknown_value = np.nan), ['Size']),\n        ('laptop_encoder', OrdinalEncoder(categories = [yesno_categories], handle_unknown = 'use_encoded_value', unknown_value = np.nan), ['Laptop Compartment']),\n        ('wp_encoder', OrdinalEncoder(categories = [yesno_categories], handle_unknown = 'use_encoded_value', unknown_value = np.nan), ['Waterproof'])\n    ],\n    remainder='passthrough'\n)\n\n# We have to use function transformer because `ord_impute` converts the DataFrame to a ndarray\n# In line with best practices using `ord_preprocessor`, we call columns by name, so we use\n# function transformer to convert our ndarray back to a DataFrame\n\nord_transformer = Pipeline(\n    steps=[\n        ('preprocess', ord_preprocessor),\n        ('ord_impute', SimpleImputer(strategy = 'median')),\n        ('df_conversion', FunctionTransformer(lambda x: pd.DataFrame(x, columns=ord_cols))),\n    ]\n)\n\n# ord_df = pd.DataFrame(ord_transformer.fit_transform(ord_df), columns = ord_cols)\nord_preprocessor.fit_transform(ord_df)\n\n# One hot columns\n\noh_transformer = Pipeline(\n    steps=[\n        ('oh_impute', SimpleImputer(strategy = 'most_frequent')),\n        ('oh_encode', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n    ]\n)\n\noh_df = pd.DataFrame(oh_transformer.fit_transform(oh_df))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T16:38:10.203899Z","iopub.execute_input":"2025-02-14T16:38:10.204177Z","iopub.status.idle":"2025-02-14T16:38:12.505213Z","shell.execute_reply.started":"2025-02-14T16:38:10.204155Z","shell.execute_reply":"2025-02-14T16:38:12.503807Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmy_model = None\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num', num_transformer, num_cols),\n        ('ord', ord_transformer, ord_cols),\n        ('oh', oh_transformer, oh_cols)\n    ],\n    remainder = 'passthrough'\n)\n\npipeline = Pipeline(\n    steps = [\n        ('preprocessor', preprocessor),\n        ('predict', my_model)\n    ]\n)\n\ntrain_total = pd.concat([train, train_xtra], axis = 0)\ntrain_total\n\nX = train_total.drop(columns = ['Price'])\ny = train_total['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train = preprocessor.fit_transform(X_train)\nX_test = preprocessor.fit_transform(X_test)\n\nX = preprocessor.fit_transform(X)\n\nprint('done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:08:37.016440Z","iopub.execute_input":"2025-02-14T17:08:37.016880Z","iopub.status.idle":"2025-02-14T17:09:15.947330Z","shell.execute_reply.started":"2025-02-14T17:08:37.016849Z","shell.execute_reply":"2025-02-14T17:09:15.946229Z"}},"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import lightgbm as lgb\n\nlgb_data = lgb.Dataset(X, label=y)\n\nparams = {\n    'objective': 'regression',  # Regression task\n    'metric': 'rmse',          # Root Mean Squared Error\n    'boosting_type': 'gbdt',   # Gradient Boosting Decision Tree\n    'num_leaves': 31,          # Number of leaves in a tree\n    'learning_rate': 0.05,     # Learning rate\n    'feature_fraction': 0.9,   # Fraction of features used for training\n    'bagging_fraction': 0.8,   # Fraction of data used for training\n    'bagging_freq': 5,         # Frequency for bagging\n    'verbose': -1              # Suppress output\n}\n\n# Computationally time consuming to run\n#\n# cv_results = lgb.cv(\n#     params,                    # Hyperparameters\n#     lgb_data,                  # Dataset\n#     num_boost_round=200,       # Number of boosting rounds\n#     nfold=5,                   # Number of folds for cross-validation\n#     stratified=False,          # Stratified sampling (not needed for regression)\n#     shuffle=True,              # Shuffle data before splitting\n#     metrics='rmse',            # Evaluation metric\n#     seed=42,                    # Random seed for reproducibility\n#     callbacks=[\n#         lgb.early_stopping(stopping_rounds=5), # callbacks introduced in lgbm version 4\n#     ]\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:09:24.368063Z","iopub.execute_input":"2025-02-14T17:09:24.368433Z","iopub.status.idle":"2025-02-14T17:13:29.110532Z","shell.execute_reply.started":"2025-02-14T17:09:24.368405Z","shell.execute_reply":"2025-02-14T17:13:29.109414Z"}},"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 5 rounds\nDid not meet early stopping. Best iteration is:\n[200]\tcv_agg's valid rmse: 38.8983 + 0.0280736\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"best_num_boost_rounds = len(cv_results['valid rmse-mean'])\nbest_rmse = min(cv_results['valid rmse-mean'])\nprint(f\"Best number of boosting rounds: {best_num_boost_rounds}\")\nprint(f\"Best RMSE: {best_rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:13:53.185858Z","iopub.execute_input":"2025-02-14T17:13:53.186230Z","iopub.status.idle":"2025-02-14T17:13:53.191908Z","shell.execute_reply.started":"2025-02-14T17:13:53.186200Z","shell.execute_reply":"2025-02-14T17:13:53.190731Z"}},"outputs":[{"name":"stdout","text":"Best number of boosting rounds: 200\nBest RMSE: 38.89825077082075\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"final_model = lgb.train(\n    params,\n    lgb_data,\n    num_boost_round=best_num_boost_rounds\n)\n\n# Save the model\nfinal_model.save_model('lightgbm_final_model.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:15:12.501088Z","iopub.execute_input":"2025-02-14T17:15:12.501437Z","iopub.status.idle":"2025-02-14T17:15:59.334902Z","shell.execute_reply.started":"2025-02-14T17:15:12.501411Z","shell.execute_reply":"2025-02-14T17:15:59.333352Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<lightgbm.basic.Booster at 0x797a7570faf0>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"loaded_model = lgb.Booster(model_file='lightgbm_final_model.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:20:00.498776Z","iopub.execute_input":"2025-02-14T17:20:00.499130Z","iopub.status.idle":"2025-02-14T17:20:00.513872Z","shell.execute_reply.started":"2025-02-14T17:20:00.499102Z","shell.execute_reply":"2025-02-14T17:20:00.512186Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"<lightgbm.basic.Booster at 0x797a7570ee00>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"y_pred = final_model.predict(preprocessor.fit_transform(test), num_iteration=final_model.best_iteration)\ny_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:23:46.461463Z","iopub.execute_input":"2025-02-14T17:23:46.461853Z","iopub.status.idle":"2025-02-14T17:23:48.160769Z","shell.execute_reply.started":"2025-02-14T17:23:46.461823Z","shell.execute_reply":"2025-02-14T17:23:48.159838Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"array([81.07832975, 82.5180992 , 82.32079065, ..., 83.09118366,\n       82.15346162, 81.24599555])"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"submission = pd.DataFrame({'Price': y_pred})\nsubmission = submission.set_index(test.index)\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:24:47.809299Z","iopub.execute_input":"2025-02-14T17:24:47.809635Z","iopub.status.idle":"2025-02-14T17:24:47.820918Z","shell.execute_reply.started":"2025-02-14T17:24:47.809609Z","shell.execute_reply":"2025-02-14T17:24:47.819818Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"            Price\nid               \n300000  81.078330\n300001  82.518099\n300002  82.320791\n300003  80.687047\n300004  78.322768\n...           ...\n499995  79.892537\n499996  77.773016\n499997  83.091184\n499998  82.153462\n499999  81.245996\n\n[200000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>300000</th>\n      <td>81.078330</td>\n    </tr>\n    <tr>\n      <th>300001</th>\n      <td>82.518099</td>\n    </tr>\n    <tr>\n      <th>300002</th>\n      <td>82.320791</td>\n    </tr>\n    <tr>\n      <th>300003</th>\n      <td>80.687047</td>\n    </tr>\n    <tr>\n      <th>300004</th>\n      <td>78.322768</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499995</th>\n      <td>79.892537</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>77.773016</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>83.091184</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>82.153462</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>81.245996</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows Ã— 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"submission.to_csv('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T17:25:07.147613Z","iopub.execute_input":"2025-02-14T17:25:07.148035Z","iopub.status.idle":"2025-02-14T17:25:07.541118Z","shell.execute_reply.started":"2025-02-14T17:25:07.148002Z","shell.execute_reply":"2025-02-14T17:25:07.539976Z"}},"outputs":[],"execution_count":55}]}